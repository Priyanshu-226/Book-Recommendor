import os
import asyncio
from dotenv import load_dotenv
from groq_llama import ask_llama

# Load API key
load_dotenv()

def get_user_input():
    query = input("üìö Enter a book name: ")
    profile = input("üë§ Optional: Describe your reading preferences (or leave blank): ")
    return query, profile

async def main():
    query, profile = get_user_input()

    if not query:
        print("‚ö†Ô∏è  Book query is required.")
        return

    prompt = f"Suggest 5 similar books to '{query}' based on the user's preferences: {profile}"
    print("\n‚è≥ Fetching recommendations...\n")

    try:
        response = await ask_llama(prompt)
        print("‚úÖ Book Recommendations:\n")
        print(response)
    except Exception as e:
        print(f"‚ùå Error: {e}")

if __name__ == "__main__":
    asyncio.run(main())
